---
title: "Linear Regression Model"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(broom)
library(caret)
library(sf)
```


```{r datasets, include=FALSE}
clim <- read.csv("data/YCOM_2019_Data.csv")
us_cov <- read.csv("us_covid.csv")
state <- read.csv("data/state_data.csv")

#modified Google dataset containing only US entries, no global
global_covid <- read.csv(file = 'Global_Mobility_Report.csv')
us_covid <- global_covid %>%
  filter(country_region_code == "US")

#YCOM climate data
YCOM <- read.csv(file = 'data/YCOM_2019_Metadata.csv')

#societal COVID predictors dataset
social_distancing <- read.csv(file = 'data/State Social Distancing Actions.csv')

#dataset combining climate variables, climate scores, and COVID factors by state
new_state <- read.csv('data/new_state.csv')

#new_state except with no NAs
new_new_state <- read.csv('data/new_new_state.csv')
```


```{r climate score}
clim[10,3]<- "District Of Columbia"
score_func<- function(region){
  dat<-clim %>%
    filter(GeoName == region) %>%
    select(human,consensus,worried,futuregen,personal,harmUS) 
  
  rowSums(dat, na.rm = FALSE) / 6
}

state<- state %>%
  mutate(score=0)

  stat<-state[1,1]
stat
for(i in 1:51){
  stat<-state[i,1]
  s<-score_func(stat)
  state[i,77]<-s
}

scores <- state %>%
  select(State, score)

new_state <- merge(state, scores, by="State")
```


{r ignore this for now}
us_covid<- us_cov %>%
  slice(-(1:158)) %>%
  mutate(score)

n<-dim(us_covid)
n<-n/2
n<-n/2
for(i in 1:n){
  stat<-toString(us_covid[i,4])
    s<-score_func(stat)
  us_covid[i,15]<-s
}

us_covid %>%
  select(score)


```{r model & predictive accuracy, message = F, warning = F}
#create training and test sets
set.seed(100)
training.samples <- new_new_state$score.y %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- new_new_state[training.samples, ]
test.data <- new_new_state[-training.samples, ]

#fit model to training set
#for each model, take note of overall r^2, p-values of predictors, and VIF values of predictors
#sensitivity analysis: get rid of high VIF predictors and see if that meaningfully affects results

#final model
lm_model <- lm(score.y ~ transit_stations_percent_change_from_baseline + bar_closures + retail_and_recreation_percent_change_from_baseline + parks_percent_change_from_baseline, na.action=na.omit, data = train.data)

#potentially important: transit_stations_percent_change_from_baseline, bar_closures, retail_and_recreation_percent_change_from_baseline

#throw away: grocery_and_pharmacy_percent_change_from_baseline, workplaces_percent_change_from_baseline, status_of_reopening, residential_percent_change_from_baseline

#maybe: parks_percent_change_from_baseline

tidy(lm_model)

summary(lm_model)

predictions <- lm_model %>% predict(test.data)

#Prediction error: RMSE
RMSE(predictions, test.data$score.y)
```


```{r detect collinearity, message = F, warning = F}
#GVIF above ~6 should be removed from the model
car::vif(lm_model)
```


```{r linear assumptions, message = F, warning = F}
lm_model_res <- augment(lm_model)

ggplot(data = lm_model_res, mapping = aes(x = .std.resid)) + 
  geom_histogram(binwidth = 1) + 
  labs(x = "Residuals", y = "Count",
       title = "Residuals are Roughly Normally Distributed")

ggplot(data = lm_model_res, mapping = aes(x = .fitted, y = .std.resid)) + 
  geom_point() + labs(x = "Fitted Values", y = "Residuals", 
                      title = "Variance Appears to be Homogenous")
```


```{r other models, message = F, warning = F}

state1 <- state%>%
  filter(stay_at_home_order!= "NA")

#some possibly interesting individual predictors that appear significant
mod1<- lm(score ~ stay_at_home_order, data=state1)

mod2 <- lm(score ~ as.factor(mandatory_quarantine_for_travelers), data=state)

mod3 <- lm(score ~ as.factor(bar_closures), data=state)

tidy(mod2)
glance(mod2)
tidy(mod1)
glance(mod1)
tidy(mod3)
glance(mod3)
```


```{r visualizations}
#sample visualizations
library(ggplot2)
library(maps)
library(mapdata)
library(tidyverse)
library(sf)
usa <- map_data("usa")
state <- read.csv("data/state_data.csv")
state <- state %>%

mutate(bar_closures)



state %>% 
  filter(BIR74 > 10000) %>% 
  select(NAME, BIR74) %>% 
  st_drop_geometry()
nc <- nc %>%
  mutate(avesids79 = SID79 / BIR79)

ggplot(nc) +
  geom_sf(aes(fill = avesids79)) +
  scale_fill_gradient(low = "#fee8c8", high ="#7f0000") +
  theme_bw()


#retail and recreation percent change in baseline


usa <- map_data("usa")
ggplot(data = state) + 
   geom_sf(aes(fill = bar_closure)) +
  theme_bw()

```
ggplot(data = usa) +
  geom_sf(color = "purple", fill = "lightblue") +
  theme_bw()


ggplot(data = usa) +
  geom_sf(aes(fill = group)) +
  scale_fill_gradient(low = "#fee8c8", high ="#7f0000") +
  theme_bw()
```{r}
library(usmap)
library(ggplot2)
state <- read.csv("data/state_data.csv")
plot_usmap(data = state, values = "bar_closures", color = "red") + 
  scale_fill_continuous(name = "Population (2015)", label = scales::comma) + 
  theme(legend.position = "right")
```
  
```{r}
state <- read.csv("data/state_data.csv")
usa <- map_data("usa")
ggplot(data = state) + 
   geom_sf(aes(fill = "bar_closure")) +
  theme_bw()

```

```{r}
new_new_state <- read.csv('data/new_new_state.csv')
var1 <- new_new_state %>% 
  select(retail_and_recreation_percent_change_from_baseline) %>%
  pull() 

states <- states %>%
  mutate(rec = var1)
usa <- map_data("usa")
ggplot(data = states) + 
   geom_sf(aes(fill = retail_recreation_percent_change_from_baseline)) +
  theme_bw()

```
```{r}
usa <- map_data("usa")
ggplot(data = state) + 
   geom_sf(aes(fill =)) +
  theme_bw()
```
```{r}
library(ggeffects)
lm_model <- lm(score.y ~ transit_stations_percent_change_from_baseline + bar_closures + retail_and_recreation_percent_change_from_baseline + parks_percent_change_from_baseline, na.action=na.omit, data = train.data)
predict3d::ggPredict(lm_model)
```

