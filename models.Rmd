---
title: "Models"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(broom)
library(caret)

clim <- read.csv("data/YCOM_2019_Data.csv")
us_cov <- read.csv("us_covid.csv")
state <- read.csv("data/state_data.csv")
```


```{r datasets, include=FALSE}
#modified Google dataset containing only US entries, no global
global_covid <- read.csv(file = 'Global_Mobility_Report.csv')
us_covid <- global_covid %>%
  filter(country_region_code == "US")
write.csv(us_covid,'us_covid.csv')

#climate data
YCOM <- read.csv(file = 'YCOM_2019_Metadata.csv')

#social factors dataset
social_distancing <- read.csv(file = 'data/State Social Distancing Actions.csv')

#dataset combining climate variables, climate score, and COVID factors by state
write.csv(new_state,'data/new_state.csv')

#new_state except with no NAs
new_new_state <- read.csv('data/new_new_state.csv')
```


```{r climate_score}
clim[10,3]<- "District Of Columbia"
score_func<- function(region){
  dat<-clim %>%
    filter(GeoName == region) %>%
    select(human,consensus,worried,futuregen,personal,harmUS) 
  
  rowSums(dat, na.rm = FALSE) / 6
}

state<- state %>%
  mutate(score=0)

  stat<-state[1,1]
stat
for(i in 1:51){
  stat<-state[i,1]
  s<-score_func(stat)
  state[i,77]<-s
}

scores <- state %>%
  select(State, score)

new_state <- merge(state, scores, by="State")
```


{r ignore this for now}
us_covid<- us_cov %>%
  slice(-(1:158)) %>%
  mutate(score)

n<-dim(us_covid)
n<-n/2
n<-n/2
for(i in 1:n){
  stat<-toString(us_covid[i,4])
    s<-score_func(stat)
  us_covid[i,15]<-s
}

us_covid %>%
  select(score)


```{r model & predictive accuracy, message = F, warning = F}
#create training and test sets
set.seed(100)
training.samples <- new_new_state$score.y %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- new_new_state[training.samples, ]
test.data <- new_new_state[-training.samples, ]

#fit model to training set
#model to play around with
#for each model, take note of overall r^2, p-values of predictors, and VIF values of predictors
#sensitivity analysis: get rid of high VIF predictors and see if that meaningfully affects results
lm_model <- lm(score.y ~ transit_stations_percent_change_from_baseline + bar_closures + retail_and_recreation_percent_change_from_baseline + parks_percent_change_from_baseline, na.action=na.omit, data = train.data)

#potentially important: transit_stations_percent_change_from_baseline, bar_closures, retail_and_recreation_percent_change_from_baseline

#throw away: grocery_and_pharmacy_percent_change_from_baseline, workplaces_percent_change_from_baseline, status_of_reopening, residential_percent_change_from_baseline

#maybe: parks_percent_change_from_baseline

tidy(lm_model)

summary(lm_model)

predictions <- lm_model %>% predict(test.data)

#Prediction error, RMSE
RMSE(predictions, test.data$score.y)
```


```{r detect collinearity, message = F, warning = F}
#interaction terms will likely have high VIF, which is okay
#GVIF above ~5 should be removed from the model
car::vif(lm_model)
```


```{r assumptions, message = F, warning = F}
modall_res <- augment(modall)

ggplot(data = modall_res, mapping = aes(x = .std.resid)) + 
  geom_histogram(binwidth = 1) + 
  labs(x = "Residuals", y = "Count",
       title = "Residuals are Normally Distributed")

ggplot(data = modall_res, mapping = aes(x = .fitted, y = .std.resid)) + 
  geom_point() + labs(x = "Fitted Values", y = "Residuals", 
                      title = "Variance Appears to be Homogenous")
```


```{r other models, message = F, warning = F}
state1 <- state%>%
  filter(stay_at_home_order!= "NA")

#some possibly interesting individual predictors that appear significant
mod1<- lm(score ~ stay_at_home_order, data=state1)

mod2 <- lm(score ~ as.factor(mandatory_quarantine_for_travelers), data=state)

mod3 <- lm(score ~ as.factor(bar_closures), data=state)

tidy(mod2)
glance(mod2)
tidy(mod1)
glance(mod1)
tidy(mod3)
glance(mod3)
```


```{r visualizations}
#sample visualizations
library(ggplot2)
library(maps)
library(mapdata)
library(tidyverse)
library(sf)
usa <- map_data("usa")


#retail and recreation percent change in baseline

ggplot(data = usa) +
  geom_sf(aes(fill = group)) +
  scale_fill_gradient(low = "#fee8c8", high ="#7f0000") +
  theme_bw()


usa <- map_data("usa")
ggplot(data = states) + 
   geom_sf(aes(fill = )) +
  theme_bw()

```

